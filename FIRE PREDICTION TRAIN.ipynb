{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f0c38c4-73e5-413f-8774-4c77efda390a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  time   lat    lon    TMP_sfc     RH_2m  APCP_sfc\n",
      "0  2002-01-01 09:00:00  21.0  88.00  297.15700  58.58463       NaN\n",
      "1  2002-01-01 09:00:00  21.0  88.25  297.08203  56.35963       NaN\n",
      "2  2002-01-01 09:00:00  21.0  88.50  297.03200  54.65963       NaN\n",
      "3  2002-01-01 09:00:00  21.0  88.75  296.98203  53.65963       NaN\n",
      "4  2002-01-01 09:00:00  21.0  89.00  297.03200  53.23463       NaN\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv('final_merged_weather_data.csv')\n",
    "\n",
    "# Display the first few rows\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "620b7c8b-cfc9-4de8-bc21-6fa18225e7bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     firedate sourcetype  longitude  latitude    state  district\n",
      "0  2003-02-03      MODIS     93.411    23.655  MIZORAM  CHAMPHAI\n",
      "1  2003-02-03      MODIS     92.847    23.695  MIZORAM    AIZAWL\n",
      "2  2003-02-03      MODIS     92.856    23.696  MIZORAM    AIZAWL\n",
      "3  2003-02-03      MODIS     92.845    23.704  MIZORAM    AIZAWL\n",
      "4  2003-02-03      MODIS     92.845    23.704  MIZORAM    AIZAWL\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv('final_file_point_2003-2024.csv')\n",
    "\n",
    "# Display the first few rows\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f99befb4-614f-4552-a21c-c6633b97b8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load weather data\n",
    "weather_df = pd.read_csv(\"final_merged_weather_data.csv\")\n",
    "fire_df = pd.read_csv(\"final_file_point_2003-2024.csv\")\n",
    "\n",
    "# Convert timestamp to datetime for merging\n",
    "weather_df['time'] = pd.to_datetime(weather_df['time'])\n",
    "fire_df['firedate'] = pd.to_datetime(fire_df['firedate'])\n",
    "\n",
    "# Convert Kelvin to Celsius for temperature\n",
    "weather_df['TMP_sfc'] = weather_df['TMP_sfc'] - 273.15\n",
    "\n",
    "# Handling missing precipitation (APCP_sfc) by filling with 0 (assuming no rain)\n",
    "weather_df['APCP_sfc'] = weather_df['APCP_sfc'].fillna(0)\n",
    "\n",
    "# Round latitude and longitude to match precision\n",
    "weather_df['lat'] = weather_df['lat'].round(2)\n",
    "weather_df['lon'] = weather_df['lon'].round(2)\n",
    "fire_df['latitude'] = fire_df['latitude'].round(2)\n",
    "fire_df['longitude'] = fire_df['longitude'].round(2)\n",
    "\n",
    "# Add fire risk label (1 = Fire, 0 = No Fire)\n",
    "fire_df['fire_risk'] = 1\n",
    "\n",
    "# Merge datasets on latitude, longitude, and nearest timestamp\n",
    "merged_df = pd.merge(weather_df, fire_df, left_on=['lat', 'lon'], right_on=['latitude', 'longitude'], how='left')\n",
    "\n",
    "# Fill missing fire_risk values (no fire cases)\n",
    "merged_df['fire_risk'] = merged_df['fire_risk'].fillna(0)\n",
    "\n",
    "# Select relevant features\n",
    "merged_df = merged_df[['APCP_sfc', 'RH_2m', 'TMP_sfc', 'fire_risk']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "042596ad-9d84-4c66-920b-43f5bc374b99",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "With n_samples=0, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 45\u001b[0m\n\u001b[1;32m     42\u001b[0m y \u001b[38;5;241m=\u001b[39m merged_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfire_risk\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# 4️⃣ Train-test split (efficiently load in batches)\u001b[39;00m\n\u001b[0;32m---> 45\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_test_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m# 5️⃣ Train Random Forest Model (optimized for large datasets)\u001b[39;00m\n\u001b[1;32m     48\u001b[0m model \u001b[38;5;241m=\u001b[39m RandomForestClassifier(n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m200\u001b[39m, max_depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m15\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/utils/_param_validation.py:216\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    211\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    212\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    213\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    214\u001b[0m         )\n\u001b[1;32m    215\u001b[0m     ):\n\u001b[0;32m--> 216\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    222\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    223\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    224\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    225\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    226\u001b[0m     )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/model_selection/_split.py:2851\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   2848\u001b[0m arrays \u001b[38;5;241m=\u001b[39m indexable(\u001b[38;5;241m*\u001b[39marrays)\n\u001b[1;32m   2850\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m _num_samples(arrays[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m-> 2851\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m \u001b[43m_validate_shuffle_split\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2852\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault_test_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.25\u001b[39;49m\n\u001b[1;32m   2853\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2855\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m shuffle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[1;32m   2856\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stratify \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/model_selection/_split.py:2481\u001b[0m, in \u001b[0;36m_validate_shuffle_split\u001b[0;34m(n_samples, test_size, train_size, default_test_size)\u001b[0m\n\u001b[1;32m   2478\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(n_train), \u001b[38;5;28mint\u001b[39m(n_test)\n\u001b[1;32m   2480\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_train \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 2481\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2482\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWith n_samples=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, test_size=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m and train_size=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2483\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresulting train set will be empty. Adjust any of the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2484\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maforementioned parameters.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_samples, test_size, train_size)\n\u001b[1;32m   2485\u001b[0m     )\n\u001b[1;32m   2487\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m n_train, n_test\n",
      "\u001b[0;31mValueError\u001b[0m: With n_samples=0, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 1️⃣ Load the large datasets in chunks (to handle memory issues)\n",
    "weather_file = \"final_merged_weather_data.csv\"\n",
    "fire_file = \"final_file_point_2003-2024.csv\"\n",
    "\n",
    "# Use `low_memory=False` to prevent dtype guessing issues\n",
    "weather_df = pd.read_csv(weather_file, low_memory=False)\n",
    "fire_df = pd.read_csv(fire_file, low_memory=False)\n",
    "\n",
    "# 2️⃣ Preprocess: Merge datasets based on latitude, longitude, and date\n",
    "fire_df['firedate'] = pd.to_datetime(fire_df['firedate'])\n",
    "weather_df['time'] = pd.to_datetime(weather_df['time'])\n",
    "\n",
    "# Round lat/lon to match (if necessary)\n",
    "weather_df[\"lat\"] = weather_df[\"lat\"].round(2)\n",
    "weather_df[\"lon\"] = weather_df[\"lon\"].round(2)\n",
    "fire_df[\"latitude\"] = fire_df[\"latitude\"].round(2)\n",
    "fire_df[\"longitude\"] = fire_df[\"longitude\"].round(2)\n",
    "\n",
    "# Merge datasets on lat/lon & time\n",
    "merged_df = fire_df.merge(\n",
    "    weather_df, \n",
    "    left_on=['firedate', 'latitude', 'longitude'], \n",
    "    right_on=['time', 'lat', 'lon'], \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Drop NaNs (optional: consider imputation if needed)\n",
    "merged_df.dropna(subset=['APCP_sfc', 'RH_2m', 'TMP_sfc'], inplace=True)\n",
    "\n",
    "# Create target column (binary fire risk: 1 if fire occurred, 0 otherwise)\n",
    "merged_df['fire_risk'] = 1\n",
    "\n",
    "# 3️⃣ Select features and target\n",
    "X = merged_df[['APCP_sfc', 'RH_2m', 'TMP_sfc']]\n",
    "y = merged_df['fire_risk']\n",
    "\n",
    "# 4️⃣ Train-test split (efficiently load in batches)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 5️⃣ Train Random Forest Model (optimized for large datasets)\n",
    "model = RandomForestClassifier(n_estimators=200, max_depth=15, n_jobs=-1, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 6️⃣ Evaluate Model Performance\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"🔥 Model Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "# 7️⃣ Save Model\n",
    "with open(\"fire_model.pkl\", \"wb\") as model_file:\n",
    "    pickle.dump(model, model_file)\n",
    "\n",
    "print(\"✅ Model saved as fire_model.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3991aa7-ca95-4a83-9e9f-cc6c3e013a8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged DF Shape: (0, 13)\n",
      "Merged DF Preview:\n",
      " Empty DataFrame\n",
      "Columns: [firedate, sourcetype, longitude, latitude, state, district, time, lat, lon, TMP_sfc, RH_2m, APCP_sfc, fire_risk]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "print(\"Merged DF Shape:\", merged_df.shape)\n",
    "print(\"Merged DF Preview:\\n\", merged_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86100f65-e765-46f3-b484-f1ce7dd40d9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔥 Fire DataFrame Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 757563 entries, 0 to 757562\n",
      "Data columns (total 6 columns):\n",
      " #   Column      Non-Null Count   Dtype         \n",
      "---  ------      --------------   -----         \n",
      " 0   firedate    757563 non-null  datetime64[ns]\n",
      " 1   sourcetype  757563 non-null  object        \n",
      " 2   longitude   757563 non-null  float64       \n",
      " 3   latitude    757563 non-null  float64       \n",
      " 4   state       757563 non-null  object        \n",
      " 5   district    757563 non-null  object        \n",
      "dtypes: datetime64[ns](1), float64(2), object(3)\n",
      "memory usage: 34.7+ MB\n",
      "None\n",
      "🌧️ Weather DataFrame Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 13230016 entries, 0 to 13230015\n",
      "Data columns (total 6 columns):\n",
      " #   Column    Dtype         \n",
      "---  ------    -----         \n",
      " 0   time      datetime64[ns]\n",
      " 1   lat       float64       \n",
      " 2   lon       float64       \n",
      " 3   TMP_sfc   float64       \n",
      " 4   RH_2m     float64       \n",
      " 5   APCP_sfc  float64       \n",
      "dtypes: datetime64[ns](1), float64(5)\n",
      "memory usage: 605.6 MB\n",
      "None\n",
      "\n",
      "📌 Fire Data Sample:\n",
      "    firedate sourcetype  longitude  latitude    state  district\n",
      "0 2003-02-03      MODIS      93.41     23.66  MIZORAM  CHAMPHAI\n",
      "1 2003-02-03      MODIS      92.85     23.70  MIZORAM    AIZAWL\n",
      "2 2003-02-03      MODIS      92.86     23.70  MIZORAM    AIZAWL\n",
      "3 2003-02-03      MODIS      92.84     23.70  MIZORAM    AIZAWL\n",
      "4 2003-02-03      MODIS      92.84     23.70  MIZORAM    AIZAWL\n",
      "\n",
      "🌍 Weather Data Sample:\n",
      "                 time   lat    lon    TMP_sfc     RH_2m  APCP_sfc\n",
      "0 2002-01-01 09:00:00  21.0  88.00  297.15700  58.58463       NaN\n",
      "1 2002-01-01 09:00:00  21.0  88.25  297.08203  56.35963       NaN\n",
      "2 2002-01-01 09:00:00  21.0  88.50  297.03200  54.65963       NaN\n",
      "3 2002-01-01 09:00:00  21.0  88.75  296.98203  53.65963       NaN\n",
      "4 2002-01-01 09:00:00  21.0  89.00  297.03200  53.23463       NaN\n"
     ]
    }
   ],
   "source": [
    "print(\"🔥 Fire DataFrame Info:\")\n",
    "print(fire_df.info())  # Check column types and missing values\n",
    "\n",
    "print(\"🌧️ Weather DataFrame Info:\")\n",
    "print(weather_df.info())  # Check column types and missing values\n",
    "\n",
    "print(\"\\n📌 Fire Data Sample:\")\n",
    "print(fire_df.head())\n",
    "\n",
    "print(\"\\n🌍 Weather Data Sample:\")\n",
    "print(weather_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00f4a889-b204-4223-9033-9cb59bb70b42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Merged Data Shape: (127, 13)\n",
      "     firedate sourcetype  longitude  latitude    state district        time  \\\n",
      "0  2004-04-30      MODIS      92.50      23.0  MIZORAM  LUNGLEI  2004-04-30   \n",
      "1  2004-04-30      MODIS      92.50      23.0  MIZORAM  LUNGLEI  2004-04-30   \n",
      "2  2004-04-30      MODIS      92.50      23.0  MIZORAM  LUNGLEI  2004-04-30   \n",
      "3  2004-04-30      MODIS      92.50      23.0  MIZORAM  LUNGLEI  2004-04-30   \n",
      "4  2007-02-28      MODIS      92.75      24.0  MIZORAM   AIZAWL  2007-02-28   \n",
      "\n",
      "    lat    lon  TMP_sfc  RH_2m  APCP_sfc  fire_risk  \n",
      "0  23.0  92.50      NaN    NaN    2.5000          1  \n",
      "1  23.0  92.50      NaN    NaN    0.6875          1  \n",
      "2  23.0  92.50      NaN    NaN    2.0000          1  \n",
      "3  23.0  92.50      NaN    NaN    0.5625          1  \n",
      "4  24.0  92.75      NaN    NaN    0.8125          1  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 🔹 Load data (if not already loaded)\n",
    "fire_df = pd.read_csv(\"final_file_point_2003-2024.csv\", parse_dates=['firedate'])\n",
    "weather_df = pd.read_csv(\"final_merged_weather_data.csv\", parse_dates=['time'])\n",
    "\n",
    "# ✅ Step 1: Convert timestamps to date format for matching\n",
    "fire_df['firedate'] = fire_df['firedate'].dt.date  # Remove time part\n",
    "weather_df['time'] = weather_df['time'].dt.date    # Remove time part\n",
    "\n",
    "# ✅ Step 2: Keep only weather data from 2003 onwards\n",
    "weather_df = weather_df[weather_df['time'] >= fire_df['firedate'].min()]\n",
    "\n",
    "# ✅ Step 3: Round lat/lon for better matching (1 km precision)\n",
    "fire_df['latitude'] = fire_df['latitude'].round(2)\n",
    "fire_df['longitude'] = fire_df['longitude'].round(2)\n",
    "weather_df['lat'] = weather_df['lat'].round(2)\n",
    "weather_df['lon'] = weather_df['lon'].round(2)\n",
    "\n",
    "# ✅ Step 4: Drop rows where precipitation is missing\n",
    "weather_df = weather_df.dropna(subset=['APCP_sfc'])\n",
    "\n",
    "# ✅ Step 5: Merge datasets (matching date, lat, lon)\n",
    "merged_df = fire_df.merge(\n",
    "    weather_df,\n",
    "    left_on=['firedate', 'latitude', 'longitude'],\n",
    "    right_on=['time', 'lat', 'lon'],\n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "# ✅ Step 6: Add target column (fire risk = 1 since fire occurred)\n",
    "merged_df['fire_risk'] = 1\n",
    "\n",
    "print(f\"✅ Merged Data Shape: {merged_df.shape}\")\n",
    "print(merged_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "22faac0e-8c9b-410e-9d45-06a98b902b5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Cleaned dataset saved as cleaned_merged_data.csv\n"
     ]
    }
   ],
   "source": [
    "merged_df['TMP_sfc'] = merged_df['TMP_sfc'].fillna(merged_df['TMP_sfc'].mean())\n",
    "merged_df['RH_2m'] = merged_df['RH_2m'].fillna(merged_df['RH_2m'].mean())\n",
    "# Save the cleaned dataset\n",
    "merged_df.to_csv(\"cleaned_merged_data.csv\", index=False)\n",
    "print(\"✅ Cleaned dataset saved as cleaned_merged_data.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "21e90aee-6e80-40dd-805d-0ca5fee008d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔥 Model Accuracy: 1.00\n",
      "✅ Model saved as fire_model.pkl\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the cleaned merged dataset\n",
    "merged_df = pd.read_csv(\"cleaned_merged_data.csv\")  # Ensure the cleaned dataset is saved\n",
    "\n",
    "# Selecting features and target variable\n",
    "X = merged_df[['TMP_sfc', 'RH_2m', 'APCP_sfc']]\n",
    "y = merged_df['fire_risk']\n",
    "\n",
    "# Train-test split (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the Random Forest model with tuned hyperparameters\n",
    "model = RandomForestClassifier(n_estimators=200, max_depth=10, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate model accuracy\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"🔥 Model Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "# Save the trained model\n",
    "with open(\"fire_model.pkl\", \"wb\") as model_file:\n",
    "    pickle.dump(model, model_file)\n",
    "\n",
    "print(\"✅ Model saved as fire_model.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "27382f0b-6b22-43c0-ae0a-63bc501f75a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Assuming your trained model is named `model`\n",
    "with open(\"fire_model.pkl\", \"wb\") as file:\n",
    "    pickle.dump(model, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87d03b7-4be6-4fbb-9a26-f08bb46980a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
